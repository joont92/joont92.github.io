---
title: '대규모 서비스를 지탱하는 기술'
date: 2019-05-07 17:27:24
tags:
---

# 대규모 서비스와 소규모 서비스
구글의 서비스 규모를 예측해보고싶다면..  
<https://www.google.com/search?q=%EA%B5%AC%EA%B8%80+%EC%84%9C%EB%B2%84+%ED%81%AC%EA%B8%B0&oq=%EA%B5%AC%EA%B8%80+%EC%84%9C%EB%B2%84+%ED%81%AC%EA%B8%B0&aqs=chrome..69i57.3570j0j1&sourceid=chrome&ie=UTF-8>  

## 소규모 서비스와 대규모 서비스 차이
- 확장성 확보, 부하분산 필요
    - 스케일 아웃을 통한 부하분산
    - 로드 밸런서를 통한 요청 분배, 분산 데이터베이스 서버간 데이터 동기화, 분산 서버간 네트워크 통신 지연시간(latency) 등을 신경써야함
- 다중성 확보
    - 다중화된 서버 중 특정 서버가 고장나더라도 서비스가 중지되지 않아야함
- 효율적 운용 필요
    - 모니터링, CI/CD 등등
- 개발자 수, 개발 방법의 변화
    - 개발 표준화(통일된 언어, 프레임워크 등)
    - 이를 지키지 않는다면 생산성이 더 떨어짐

## 대규모 데이터량에 대한 대처
대규모 웹 어플리케이션 운용의 어려움은 대부분 대규모 데이터 처리에 집중됨  
데이터가 적을때는 간단한 알고리즘으로 모두 메모리에서 처리할 수 있지만, 대규모 데이터는 그게 힘들기 떄문이다  
그러므로 여러가지 전략(캐싱 등등)을 고민해야함  

## 웹 서비스의 어려움
웹 서비스의 또 다른 큰 어려움 중 하나는 서비스가 계속해서 성장해나간다는 것이다  
하지만 처음부터 대규모를 예측하여 완벽한 부하분산 시스템을 설계하기에는 비용이 너무 많이 들고, 또한 웹 서비스가 그렇게까지 성공한다는 보장도 없다(웹 서비스는 성공 확률이 낮다)  

# 대규모 데이터의 양
초대규모 서비스의 경우 테이블하나가 N백기가, N테라 단위가 넘어가기도 하지만 그런 경우는 많지않고, 보통 N기가 단위로만 넘어가도 대규모라고 볼 수 있다  
e.g. 1500만개의 레코드를 가진 테이블(3GB), 4500만개의 레코드를 가진 테이블(6GB)  

이 정도의 데이터를 인덱스없이 읽어보면 수백초가 걸리므로(select * from table), 조치가 필요하다  

# 대규모 데이터의 어려운 점
- 메모리내에서 계산할 수 없다
    - 데이터가 너무 많기 때문이다
- 메모리와 디스크의 속도차는 10^5~10^6배(10만~100만배) 정도 차이가 난다(탐색속도)
- 하드디스크는 데이터를 읽는데 물리적인 동작이 수반되기 때문이다
    - 원판을 돌려서 데이터를 읽어야하기 때문이다
    - 게다가 데이터가 파편화되어 있을 경우 원판을 수차례 돌려야한다
    - 디스크는 수밀리초가 걸리지만 램은 마이크로초면 된다
    - SSD가 나왔어도 당연히 램보다는 느리다 <http://www.inven.co.kr/board/diablo3/2716/13372>
- OS레벨에서 탐색속도의 문제를 그나마 줄이기 위해 디스크 모음을 해서 같은 데이터를 계속 한곳으로 모은다
    - 하나의 데이터를 읽기 위해 여러군데를 왔다갔다 거리는것을 없애기 위함
- 메모리와 디스크는 전송속도에서도 거의 100배 가까이 차이가 난다
    - 탐색속도만이 문제가 아니다

<!-- more -->