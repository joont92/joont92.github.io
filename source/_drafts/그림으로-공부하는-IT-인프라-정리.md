---
title: 그림으로 공부하는 IT 인프라 정리
tags:
---

# 서버를 열어보자
- 랙은 규격이 있다(1U = 4.5cm)
- CPU와 메모리는 물리적으로 연결되어 있다
- HDD나 NIC는 메모리에 비해 멀리 떨어져 있다
- 컴포넌트들은 버스로 연결된다
- 멀티 코어 = 1개의 CPU에 여러개의 코어
- 프로세스, 입출력 장치가 OS에 명령을 내리고, OS가 CPU에 명령을 내린다
- 메모리는 전기적 처리로 데이터를 저장하므로 매우 빠르나, 휘발성이다
- CPU도 레지스터(L1,L2,L3)라는 매우 작은 저장장치를 가지고 있다
    - 메모리 컨트롤러를 통해 메모리로 나가는 작은 레이턴시조차 줄이고 싶기 때문
- 스토리지는 HDD 여러개 외에도 캐시, CPU(?) 등이 존재한다
- 읽기 캐시의 경우 캐시에 없을 경우 하드에서 읽어서 캐시에 기록해둠
- 쓰기 캐시의 경우 캐시에 데이터를 기록하고 IO 종료?
- 네트워크 인터페이스는 외부 장비를 연결하기 위해 사용하는 것이다
- IO 장비와 CPU 사이에는 IO 핸들러라는 것이 존재한다(IOH, ICH 등)
- 대역은 한 번에 데이터를 보낼수 있는 폭, 1초에 전송할 수 있는 횟수로 결정된다
- CPU에 가까운 쪽이 버스 대역이 더 크다
    - e.g. CPU와 메모리는 대량의 데이터를 빠르게 전송하는 능력이 요구되기 때문

- 프로세스 생성을 요청하면 커널이 메모리 공간을 할당하여 생성한다
- 프로세스는 각자 메모리 공간을 가지고, 스레드는 프로세스의 메모리 공간을 공유한다
- 대체로 웹 서버는 멀티 프로세스로 동작하고(프로세스가 뜨는데 시간이 오래 걸리므로 미리 띄워놓는다), 어플리케이션 서버는 멀티 스레드로 동작하고, DB 서버는 멀티 프로세스에 공유 메모리(PGA)를 두며 동작한다(Oracle)
- 커널의 기능 : 핵심은 뒤에서 이루어지고 있는 처리는 숨기고 편리한 인터페이스를 제공한다는 사실이다  
    1. 시스템 콜 인터페이스
        OS를 통해 어떤 처리를 하고 싶을 때(네트워크 통신, 파일 IO 등) 이 시스템 콜을 이용해 커널에 명령을 내린다
    2. 프로세스 관리
        프로세스에 CPU를 할당하는 기능이다(스케줄링?)
    3. 메모리 관리
        물리 메모리 공간의 최대치를 고려하여 프로세스가 이용하는 독립 메모리 공간을 확보한다
    4. 파일 시스템 관리
        0101로 저장되어 있는 파일에 접근하는 인터페이스 역할을 한다(디렉토리, 접근관리, 고속화 등)
    5. 장치 드라이버
        물리 장치의 인터페이스를 제공한다
    6. 네트워크 스택
- 클라이언트 PC부터 웹 서버까지의 흐름은 아래와 같다
    > 본질은 요청 기반으로 어떠한 처리를 하고, 필요에 따라 요청을 3자에게 할당하는 것이다
    1. 클라이언트에서 도메인이나 IP를 통해 요청을 보낸다
    2. 웹 서버(httpd)의 자식 프로세스가(대체적으로) 요청을 받고, 디스크에서 질의할지 AP 서버에 질의할지 판단한다
        - 디스크에 있는 정보가 필요할 경우 커널에 `시스템콜`을 보내 디스크의 내용을 취득한다
        - AP 서버로 질의해야 할 경우 커널에 `시스템콜`을 보내 AP 서버와 통신한다
    3. AP 서버의 스레드가 요청을 받는다
        - DB 연결이 필요할 경우 마찬가지로 커널에 `시스템콜`을 보내 DB 서버와 통신한다
        - 규모가 큰 정적 데이터의 경우에는 CDN을 이용하는 경우도 있다?
    4. DB 서버의 프로세스가 요청을 받는다(오라클 기준)
        - 요청하는 데이터가 캐시에 있으면 바로 리턴하고, 없다면 `시스템콜`로 디스크에서 읽어온 뒤 캐시 메모리에 저장한다
        - 디스크는 DB 서버 내부에 두지 않고 별도의 저장소를 둔다. 저장소 또한 CPU, OS를 가지고 있다

- 직렬 처리 속도(클럭속도)를 올리는데는 하드웨어의 한계가 있다
- CPU 코어를 늘리더라도 작업을 병렬로 나눠서 시키지 않으면 싱글 코어와 다를게 없다
- 병렬 처리에서는 분기점, 직렬화 구간, 합류점이 병목 지점이 되기 쉽고, 오버헤드가 걸린다
    - 이 부분을 감안하더라도 효과가 있을 경우 병렬화를 하는 것이 좋다

현재 네트워크는 그 구조를 알지 못해도 사용할 수 있도록 되어있음
네트워크 데이터 처리/교환에는 다양한 구조가 존재함(3계층형 시스템을 구성하는 경우 대부분 TCP/IP를 사용함)
컴퓨터는 대부분 계층구조
	- 커질수록 계층화하지 않으면 구조가 복잡해진다
계층들간에 교환방법(인터페이스)만 정의해놓으면 됨
- 어떤일을 하는지는 알지만 어떻게 하는지는 모른다
- 인터페이스만 바꾸면 변경도 용이하다
- 대신 성능이 조금 떨어짐

커널과 JVM은 시스템콜로 연결되어있다?

네트워크 표준화 = IEEE, IETF(RFC 만듦)
OSI는 TCP/IP가 defecto라 사용되지 않는다?
우리가 아는 프로토콜 HTTP, TCP/IP 등 이런것만 프로토콜인가?
RFC는 프로토콜이 아닌가? == 인터넷 기술과 관련된 표준 문서
이건 어디서 정하는 것인가?

표준이 필요해 OSI 를 만들었지만 이미 TCP/IP가 보급되고 있었으며, OSI는 사장됨 > TCP/IP 4계층
이처럼 네트워크가 상호협력 하면서 인터넷이 발전했고, 이 가운데서 TCP/IP가 발전

TCP/IP 4계층이지만 현업에서는 OSI 레이어를 토대로 계층을 부르는 경우가 많다
이더넷 계층 L2, IP 계층 L3, 전송 계층 L4, 애플리케이션 계층 L7(5, 6을 모아서 애플리케이션 계층으로 취급하기 때문)

통신의 시작점은 애플리케이션이다
애플리케이션 계층 프로토콜은 자신이 통신을 하는 것이 아니라 모두 OS(TCP/IP)에게 맡긴다

HTTP가 하위 계층인 IP 등등을 제어하지는 않는다
단순히 요청, 헤더, 바디만 보내고 받는 간단한 구조이다

애플리케이션 계층 프로토콜은 필요한 데이터를 소켓에 기록만 하며, 통신은 모두 TCP/IP에게 위임한다
TCP/IP가 실패할 수는 없다.. 뭐 이게 그 말일까?

어플리케이션 프로세스는 시스템 콜로 커널에 TCP/IP 통신 요청을 하면서 소켓이 열리고, 열린 소켓으로 IP와 PORT 정보를 전달하면 통신이 된다
즉 TCP/IP 레벨부터는 커널단에서 다 구현되어 있다는 의미이다 == 브라우저 없이도 TCP/IP 통신은 가능하다

HTTP는 기본적으로 요청이 많고, 한번에 한 요청만 한다
> HTML 파일을 받고 파일내에 이미지나 스크립트가 있으면 다시 요청하기 떄문
이 때문에 하위 계층인 TCP/IP 에서 소켓을 열고 닫는 행위를 자주해야 되므로, 많은 오버헤드를 발생시킨다(3way hand shaking)
keep alive = https://b.pungjoo.com/entry/HTTP-11-Keep-Alive-%EA%B8%B0%EB%8A%A5%EC%97%90-%EB%8C%80%ED%95%B4
> HTTP 요청에 keep alive가 있다면 사용하던 소켓을 계속 사용하게 된다(TCP/IP 레벨)  
> 대부분 3600초라는데.. 잘 이해가 안간다  

TCP = 서버가 송신할 때와 서버가 수신한 후 애플리케이션에게 전달할 때만 담당
IP = 실제 서버까지 전송하는 부분 담당

모든 네트워크가 다 빠르지 않다. 데이터가 유실되는 경우도 굉장히 많다. 그러므로 서로간 신뢰성을 담보하는 기능이 필요하다
그리고 인터넷은 공평성도 중요하다. 보내는쪽에서 아무리 빨리줘봤자 받는쪽에서 빨리 받지 못하는 환경이면 아무 의미가 없다.
TCP는 이런 신뢰확인 시스템(+재전송)과 폭주제어 기능을 가지고 있다
IP만 가지고 통신할 수 있으나, TCP의 이런 특징 없이는 신뢰성을 가진 네트워크를 구성할 수 없는것이다
IP는 그냥 데이터를 전송하는 기능만을 담당하기 때문이다.
> 인터넷은 모두의 것이라는 생각을 가지고 접근해야 한다

어플리케이션 데이터가 소켓에 들어오면 소켓의 큐를 경유하여 소켓 버퍼라고 불리는 메모리 영역에서 처리된다
데이터는 TCP 세그먼트라는 단위(MSS)로 나눠진다
> 최종적으로 링크계층에서 데이터를 전송하기 때문에 MSS는 링크 계층에서 전송할 수 있는 최대 크기에 의존한다
MSS로 나누는 것도 TCP의 기능이다
TCP 세그먼트는 각각 TCP 헤더를 가지고 있다

전달받은 데이터를 어느 어플리케이션에 전달해야할 지 모르므로, 포트번호를 전달해줘야 한다
서버는 LISTEN 할 포트를 지정하지만 클라이언트는 송신할 포트를 지정할 수 없다
이때는 OS에서 사용하지 않는 포트번호(0~65xxx)가 자동으로 할당되어 통신한다

# 3way handshaking
1. 통신 의뢰를 받으면 소켓을 생성하기 위해 상대편 IP의 포트로 통신 요청을 한다 : SYN
2. 상대편 IP가 유효하고, 포트가 LISTEN 상태면 통신 할 수 있다는 응답을 한다 : ACK
    > ACK과 응답 데이터를 같이 전송해서 왕복 횟수를 줄인다  
    > ACK이 돌아오지 않는다면 전송에 실패했다는 것이다. 이를 대비해 소켓 버퍼에 SYN TCP 세그먼트는 남겨둬야 한다  
3. 확인했다는 메시지를 보내면 가상 경로(소켓)이 열린다
> 이런 요청이든 통신이든 결과적으로는 물리적인 선을 경유해서 이루어진다

소켓과 소켓 사이에 입력/출력 스트림 2개가 형성되어 통신한다  
소켓은 문이고, 스트림이 길일까?  
핸드쉐이킹 3번 과정에서 양쪽 소켓이 생성되고 스트림으로 연결되는걸까?  

받자마자 데이터를 바로 보내는 것은 낭비이므로 송신측에는 송신 버퍼와 송신 타이머가 존재함  
(뭐든 버퍼에 넣어서 보내는게 효율적이다)  
(송신 버퍼는 MTU 라고 불리며 보통 1500 바이트이고, 앞부분 헤더를 제외하면 1460정도가 된다. 이를 MSS 라고 한다)  
송신 버퍼에 데이터가 꽉 차면 수신측으로 데이터를 보내게 된다  
송신 버퍼에 데이터가 다 차지 않은 상태에서 일정 시간이 지나게 되면(송신 타이머) 수신측으로 데이터를 보낸다  

데이터를 분할 전송할 때 시퀀스 번호라는 것을 활용한다  
시퀀스 번호는 보통 전체 데이터에서 전달하는 데이터의 시작 바이트 숫자가 된다  
(3000바이트의 경우 1460, 1460, 80으로 나눠지므로 시퀀스 번호는 1, 1461, 2921이 된다)  
수신측에서 데이터를 받으면 다음에 받을 데이터의 시퀀스 번호로 요청하고, 송신측에서는 해당 시퀀스 번호부터 데이터를 송신한다  

데이터를 보내고 ACK를 받기전까지 보낸 데이터를 버퍼에서 삭제하지 않고 놔둔다  
ACK를 받는 순간 버퍼에서 데이터를 삭제한다  
ACK이 타임아웃 시간까지 오지 않으면 자동 재전송한다  

https://mindnet.tistory.com/entry/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EC%89%BD%EA%B2%8C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-22%ED%8E%B8-TCP-3-WayHandshake-4-WayHandshake

https://asfirstalways.tistory.com/318